{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9JxbGsxQJpqX"
      },
      "outputs": [],
      "source": [
        "%%time\n",
        "import os\n",
        "import shutil\n",
        "\n",
        "# Configuration\n",
        "DJANGO_PATH = '/content/drive/MyDrive/Google AI Studio/django-docs-5.2-en'\n",
        "INTERMEDIATE_PATH = '/content/drive/MyDrive/Google AI Studio/all_html_txt'\n",
        "\n",
        "# Define supported file extensions\n",
        "SUPPORTED_EXTENSIONS = {'.xml', '.txt', '.json', '.py', '.md', '.html', '.htm'}\n",
        "\n",
        "def get_unique_filename(destination_path, filename):\n",
        "    \"\"\"Generate unique filename by adding numeric suffix if file already exists.\"\"\"\n",
        "    full_path = os.path.join(destination_path, filename)\n",
        "\n",
        "    if not os.path.exists(full_path):\n",
        "        return filename\n",
        "\n",
        "    name, ext = os.path.splitext(filename)\n",
        "    counter = 1\n",
        "\n",
        "    while True:\n",
        "        new_filename = f\"{name}_{counter}{ext}\"\n",
        "        new_full_path = os.path.join(destination_path, new_filename)\n",
        "\n",
        "        if not os.path.exists(new_full_path):\n",
        "            return new_filename\n",
        "        counter += 1\n",
        "\n",
        "print(\"=== STEP 1: COLLECTING FILES ===\")\n",
        "\n",
        "# Clean up intermediate directory\n",
        "if os.path.exists(INTERMEDIATE_PATH):\n",
        "    print(f\"Cleaning intermediate directory: {INTERMEDIATE_PATH}\")\n",
        "    shutil.rmtree(INTERMEDIATE_PATH)\n",
        "\n",
        "os.makedirs(INTERMEDIATE_PATH, exist_ok=True)\n",
        "\n",
        "print(f\"Collecting files with extensions {SUPPORTED_EXTENSIONS}\")\n",
        "print(f\"From: {DJANGO_PATH}\")\n",
        "print(f\"To: {INTERMEDIATE_PATH}\")\n",
        "\n",
        "collected_files = 0\n",
        "files_by_extension = {}\n",
        "\n",
        "for root, _, files in os.walk(DJANGO_PATH):\n",
        "    for file in files:\n",
        "        _, ext = os.path.splitext(file)\n",
        "        ext_lower = ext.lower()\n",
        "\n",
        "        if ext_lower in SUPPORTED_EXTENSIONS:\n",
        "            source_file_path = os.path.join(root, file)\n",
        "            unique_filename = get_unique_filename(INTERMEDIATE_PATH, file)\n",
        "            destination_file_path = os.path.join(INTERMEDIATE_PATH, unique_filename)\n",
        "\n",
        "            try:\n",
        "                shutil.copy2(source_file_path, destination_file_path)\n",
        "                collected_files += 1\n",
        "                files_by_extension[ext_lower] = files_by_extension.get(ext_lower, 0) + 1\n",
        "\n",
        "                if collected_files % 100 == 0:  # Progress indicator\n",
        "                    print(f\"Collected {collected_files} files...\")\n",
        "\n",
        "            except Exception as e:\n",
        "                print(f\"Error collecting {source_file_path}: {e}\")\n",
        "\n",
        "print(f\"\\nCollection complete! Collected {collected_files} files\")\n",
        "print(\"Files by extension:\")\n",
        "for ext, count in sorted(files_by_extension.items()):\n",
        "    print(f\"  {ext}: {count} files\")\n",
        "\n",
        "print(f\"\\nFiles are ready in: {INTERMEDIATE_PATH}\")\n",
        "print(\"Ready for processing in next cell!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c3iLnUj2Q0xz"
      },
      "outputs": [],
      "source": [
        "%%time\n",
        "import os\n",
        "import shutil\n",
        "import json\n",
        "from bs4 import BeautifulSoup\n",
        "import xml.etree.ElementTree as ET\n",
        "\n",
        "# Configuration\n",
        "INTERMEDIATE_PATH = '/content/drive/MyDrive/Google AI Studio/all_html_txt'\n",
        "FINAL_PATH = '/content/drive/MyDrive/Google AI Studio/all_txt'\n",
        "\n",
        "# Helper: ensure unique filenames in any dest folder\n",
        "def get_unique_filename(destination_path, filename):\n",
        "    full_path = os.path.join(destination_path, filename)\n",
        "    if not os.path.exists(full_path):\n",
        "        return filename\n",
        "    name, ext = os.path.splitext(filename)\n",
        "    counter = 1\n",
        "    while True:\n",
        "        new_filename = f\"{name}_{counter}{ext}\"\n",
        "        if not os.path.exists(os.path.join(destination_path, new_filename)):\n",
        "            return new_filename\n",
        "        counter += 1\n",
        "\n",
        "# Content processors\n",
        "def process_html_content(content):\n",
        "    \"\"\"Process HTML content and extract clean text.\"\"\"\n",
        "    soup = BeautifulSoup(content, 'html.parser')\n",
        "    for script in soup([\"script\", \"style\"]):\n",
        "        script.decompose()\n",
        "    text = soup.get_text()\n",
        "    lines = (line.strip() for line in text.splitlines())\n",
        "    chunks = (phrase.strip() for line in lines for phrase in line.split(\"  \"))\n",
        "    cleaned = '\\n'.join(chunk for chunk in chunks if chunk)\n",
        "    return cleaned.lower()\n",
        "\n",
        "def process_xml_content(content):\n",
        "    \"\"\"Process XML content and extract text from all elements.\"\"\"\n",
        "    try:\n",
        "        root = ET.fromstring(content)\n",
        "        def extract_text(el):\n",
        "            parts = []\n",
        "            if el.text:\n",
        "                parts.append(el.text.strip())\n",
        "            for child in el:\n",
        "                parts.extend(extract_text(child))\n",
        "                if child.tail:\n",
        "                    parts.append(child.tail.strip())\n",
        "            return parts\n",
        "        parts = extract_text(root)\n",
        "        return '\\n'.join(p for p in parts if p).lower()\n",
        "    except ET.ParseError:\n",
        "        return content.lower()\n",
        "\n",
        "def process_json_content(content):\n",
        "    \"\"\"Process JSON content and extract all string values.\"\"\"\n",
        "    try:\n",
        "        data = json.loads(content)\n",
        "        def extract_strings(obj):\n",
        "            strs = []\n",
        "            if isinstance(obj, dict):\n",
        "                for k, v in obj.items():\n",
        "                    strs.append(str(k))\n",
        "                    strs.extend(extract_strings(v))\n",
        "            elif isinstance(obj, list):\n",
        "                for item in obj:\n",
        "                    strs.extend(extract_strings(item))\n",
        "            elif isinstance(obj, str):\n",
        "                strs.append(obj)\n",
        "            else:\n",
        "                strs.append(str(obj))\n",
        "            return strs\n",
        "        all_strs = extract_strings(data)\n",
        "        return '\\n'.join(all_strs).lower()\n",
        "    except json.JSONDecodeError:\n",
        "        return content.lower()\n",
        "\n",
        "def process_plain_text_content(content):\n",
        "    \"\"\"Process plain text content (for .txt, .py, .md files).\"\"\"\n",
        "    return content.lower()\n",
        "\n",
        "# STEP 2: PROCESSING TO TEXT\n",
        "print(\"=== STEP 2: PROCESSING TO TEXT ===\")\n",
        "\n",
        "if not os.path.exists(INTERMEDIATE_PATH):\n",
        "    raise FileNotFoundError(f\"Intermediate directory not found: {INTERMEDIATE_PATH}\")\n",
        "\n",
        "# Reset final directory\n",
        "tag = \"Cleaning\" if os.path.exists(FINAL_PATH) else \"Creating\"\n",
        "print(f\"{tag} final directory: {FINAL_PATH}\")\n",
        "if os.path.exists(FINAL_PATH):\n",
        "    shutil.rmtree(FINAL_PATH)\n",
        "os.makedirs(FINAL_PATH, exist_ok=True)\n",
        "\n",
        "print(f\"Processing files from: {INTERMEDIATE_PATH}\")\n",
        "print(f\"Saving processed text to: {FINAL_PATH}\")\n",
        "\n",
        "processed_files = 0\n",
        "processing_errors = 0\n",
        "files_by_type = {}\n",
        "\n",
        "for file in os.listdir(INTERMEDIATE_PATH):\n",
        "    src = os.path.join(INTERMEDIATE_PATH, file)\n",
        "    if not os.path.isfile(src):\n",
        "        continue\n",
        "    _, ext = os.path.splitext(file)\n",
        "    ext_lower = ext.lower()\n",
        "    base = os.path.splitext(file)[0]\n",
        "    # Generate unique .txt name\n",
        "    final_name = get_unique_filename(FINAL_PATH, f\"{base}.txt\")\n",
        "    dest = os.path.join(FINAL_PATH, final_name)\n",
        "    try:\n",
        "        with open(src, 'r', encoding='utf-8') as f:\n",
        "            content = f.read()\n",
        "        if ext_lower in ['.html', '.htm']:\n",
        "            text_content = process_html_content(content)\n",
        "            ftype = 'HTML'\n",
        "        elif ext_lower == '.xml':\n",
        "            text_content = process_xml_content(content)\n",
        "            ftype = 'XML'\n",
        "        elif ext_lower == '.json':\n",
        "            text_content = process_json_content(content)\n",
        "            ftype = 'JSON'\n",
        "        elif ext_lower in ['.txt', '.py', '.md']:\n",
        "            text_content = process_plain_text_content(content)\n",
        "            ftype = ext_lower.upper().replace('.', '')\n",
        "        else:\n",
        "            continue\n",
        "        with open(dest, 'w', encoding='utf-8') as f:\n",
        "            f.write(text_content)\n",
        "        processed_files += 1\n",
        "        files_by_type[ftype] = files_by_type.get(ftype, 0) + 1\n",
        "        if processed_files % 50 == 0:\n",
        "            print(f\"Processed {processed_files} files...\")\n",
        "    except UnicodeDecodeError:\n",
        "        print(f\"Encoding error (skipping binary file): {file}\")\n",
        "        processing_errors += 1\n",
        "    except Exception as e:\n",
        "        print(f\"Processing error for {file}: {e}\")\n",
        "        processing_errors += 1\n",
        "\n",
        "print(\"\\nProcessing complete!\")\n",
        "print(f\"Total files processed: {processed_files}\")\n",
        "print(f\"Processing errors: {processing_errors}\")\n",
        "print(\"Files processed by type:\")\n",
        "for t, cnt in sorted(files_by_type.items()):\n",
        "    print(f\"  {t}: {cnt} files\")\n",
        "\n",
        "print(\"\\n=== PIPELINE COMPLETE ===\")\n",
        "print(f\"RAG-ready text files available in: {FINAL_PATH}\")\n",
        "print(f\"Intermediate files are still in: {INTERMEDIATE_PATH}\")\n",
        "print(\"You can manually delete the intermediate folder if you want to save space.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nny7LcUYbdFW",
        "outputId": "052f288d-d08e-4ffe-bf1d-d20151bef3bc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: uv in /usr/local/lib/python3.11/dist-packages (0.7.13)\n"
          ]
        }
      ],
      "source": [
        "!pip install uv"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fsF_w8EHotuL",
        "outputId": "28e80818-cbe8-4dae-bcfe-e6b9a528f835"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[2mUsing Python 3.11.13 environment at: /usr\u001b[0m\n",
            "\u001b[2mAudited \u001b[1m10 packages\u001b[0m \u001b[2min 65ms\u001b[0m\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "!uv pip install python-dotenv tqdm langchain langchain-huggingface langchain-community chromadb tensorflow-hub tensorflow-text pypdf2 pymupdf\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 443,
          "referenced_widgets": [
            "be2e331a34344aceaea07fd561e823ac",
            "c08ad26d464049e1b163f71b3875d334",
            "fa64efd1b14a4a4e82c35788e337239e",
            "c387c8882da2494b9f13afc6865348f8",
            "0e6d093d41344fc09650686b34433acc",
            "4ce102cdeed94d1094e3dcfdf41d9717",
            "c3871565dbba4600b0147483d891689b",
            "b231c6538b6c4139b0eb13b30fc2d76e",
            "b5d244dade2c4552bfaddeaa93443c2a",
            "105b4489a8b0425eab93d320bbbfb834",
            "71940fd74e9c4e4da1521f08c5d48bb2",
            "9cc4f3388c564bdfbb3da5c0ee6ff878",
            "9527798d94e644c89121485a08913298",
            "1c2b957fc6384db4a84b040adc9d8383",
            "81eb2895b214464e9762b1c294cf1cf3",
            "5cb0c62103444025bf3ca674045f1000",
            "6f3dba7bec4642d6a3f3996bbf37644e",
            "85be9aafc0f14a90a59212579fa871b1",
            "f77b94b7c70944aaa54d157f41c7a8fa",
            "f053eba232464219a0122adc4fb51c30",
            "8485c82514ea45d0925aac27b446e77a",
            "1648066ad3f04af5931fcf29d5635f63",
            "4daf6dd9ea17401daec5ab9a7c3251b0",
            "04a5cbc1a6ce460094b8f76ae284c206",
            "2d72a629aab444caa10cb1e213d5f595",
            "c19e6df98ecc4cdeb0e6ea9208b358b4",
            "d41d1a0710be44e98f3fb986a49ba293",
            "7f082831e6474788ae19ac9c386829ad",
            "7180a10ed0b443d98e645aa75e17f31a",
            "58a7af7b84194c3181269b8e1d1e220f",
            "24f632c63db3441fb6673f8b6039b379",
            "917340856dcd43b4b89396d48e6554e2",
            "6bdfacf8841c4651af99734bde0e2a46"
          ]
        },
        "collapsed": true,
        "id": "RYJljlsGtpoF",
        "outputId": "416464da-7752-4b0e-df09-0ee3f5d8d165"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "üìÇ Loading .txt and .pdf files...\n",
            "Found 1777 .txt files and 0 .pdf files\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "be2e331a34344aceaea07fd561e823ac",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Loading TXT files:   0%|          | 0/1777 [00:00<?, ?file/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ Loaded 1777 text documents\n",
            "üìÑ Total documents loaded: 1777\n",
            "‚úÇÔ∏è  Splitting documents into chunks...\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "9cc4f3388c564bdfbb3da5c0ee6ff878",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Splitting docs:   0%|          | 0/1777 [00:00<?, ?doc/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "üìÑ Generated 51838 chunks from 1777 documents.\n",
            "üåê Ingesting chunks to Chroma with TPU embeddings in parallel...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<timed exec>:215: LangChainDeprecationWarning: The class `Chroma` was deprecated in LangChain 0.2.9 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-chroma package and should be used instead. To use it run `pip install -U :class:`~langchain-chroma` and import as `from :class:`~langchain_chroma import Chroma``.\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "4daf6dd9ea17401daec5ab9a7c3251b0",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Adding batches:   0%|          | 0/1037 [00:00<?, ?batch/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<timed exec>:237: LangChainDeprecationWarning: Since Chroma 0.4.x the manual persistence method is no longer supported as docs are automatically persisted.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ Database built successfully.\n",
            "üìä Summary:\n",
            "   ‚Ä¢ Total documents: 1777\n",
            "   ‚Ä¢ Text files: 1777\n",
            "   ‚Ä¢ PDF files: 0\n",
            "   ‚Ä¢ Total chunks: 51838\n",
            "CPU times: user 1h 13min 31s, sys: 59min 10s, total: 2h 12min 41s\n",
            "Wall time: 38min 19s\n"
          ]
        }
      ],
      "source": [
        "%%time\n",
        "\n",
        "\"\"\"\n",
        "create_database.py - TPU-only, fully parallel with progress bars\n",
        "\n",
        "Features:\n",
        "  ‚Ä¢ Use TPU (via TensorFlow Hub) for embeddings\n",
        "  ‚Ä¢ Load, split, embed, and ingest .txt and .pdf files in parallel\n",
        "  ‚Ä¢ Progress bars at each step using tqdm\n",
        "  ‚Ä¢ Support for multiple PDF extraction methods\n",
        "\"\"\"\n",
        "import os\n",
        "from pathlib import Path\n",
        "import json\n",
        "import time\n",
        "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
        "\n",
        "from dotenv import load_dotenv\n",
        "load_dotenv()\n",
        "\n",
        "import torch\n",
        "from tqdm.auto import tqdm\n",
        "from langchain.schema import Document\n",
        "from langchain.document_loaders import TextLoader, PyPDFLoader\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "from langchain.embeddings import TensorflowHubEmbeddings\n",
        "from langchain_community.vectorstores import Chroma\n",
        "\n",
        "# Alternative PDF loaders for better extraction\n",
        "try:\n",
        "    import fitz  # PyMuPDF\n",
        "    PYMUPDF_AVAILABLE = True\n",
        "except ImportError:\n",
        "    PYMUPDF_AVAILABLE = False\n",
        "\n",
        "try:\n",
        "    import PyPDF2\n",
        "    PYPDF2_AVAILABLE = True\n",
        "except ImportError:\n",
        "    PYPDF2_AVAILABLE = False\n",
        "\n",
        "# Paths\n",
        "DATA_DIR = Path(\"/content/drive/MyDrive/Google AI Studio/all_txt\")\n",
        "CHROMA_PATH = Path(\"/content/drive/MyDrive/Google AI Studio/chroma_db\")\n",
        "CHROMA_COLLECTION_NAME = \"rag_collection\"\n",
        "\n",
        "# Embedding via TPU\n",
        "EMBEDDING_MODEL_URL = \"https://tfhub.dev/google/universal-sentence-encoder-large/5\"\n",
        "\n",
        "def load_pdf_with_pymupdf(file_path):\n",
        "    \"\"\"Load PDF using PyMuPDF (fitz) - generally better text extraction\"\"\"\n",
        "    docs = []\n",
        "    try:\n",
        "        pdf_document = fitz.open(file_path)\n",
        "        for page_num in range(len(pdf_document)):\n",
        "            page = pdf_document.load_page(page_num)\n",
        "            text = page.get_text()\n",
        "            if text.strip():  # Only add non-empty pages\n",
        "                doc = Document(\n",
        "                    page_content=text,\n",
        "                    metadata={\n",
        "                        \"source\": str(file_path),\n",
        "                        \"page\": page_num + 1,\n",
        "                        \"total_pages\": len(pdf_document)\n",
        "                    }\n",
        "                )\n",
        "                docs.append(doc)\n",
        "        pdf_document.close()\n",
        "    except Exception as e:\n",
        "        print(f\"‚ùå PyMuPDF failed for {file_path}: {e}\")\n",
        "    return docs\n",
        "\n",
        "def load_pdf_with_pypdf2(file_path):\n",
        "    \"\"\"Load PDF using PyPDF2 - fallback method\"\"\"\n",
        "    docs = []\n",
        "    try:\n",
        "        with open(file_path, 'rb') as file:\n",
        "            pdf_reader = PyPDF2.PdfReader(file)\n",
        "            for page_num, page in enumerate(pdf_reader.pages):\n",
        "                text = page.extract_text()\n",
        "                if text.strip():  # Only add non-empty pages\n",
        "                    doc = Document(\n",
        "                        page_content=text,\n",
        "                        metadata={\n",
        "                            \"source\": str(file_path),\n",
        "                            \"page\": page_num + 1,\n",
        "                            \"total_pages\": len(pdf_reader.pages)\n",
        "                        }\n",
        "                    )\n",
        "                    docs.append(doc)\n",
        "    except Exception as e:\n",
        "        print(f\"‚ùå PyPDF2 failed for {file_path}: {e}\")\n",
        "    return docs\n",
        "\n",
        "def load_pdf_with_langchain(file_path):\n",
        "    \"\"\"Load PDF using LangChain's PyPDFLoader - another fallback\"\"\"\n",
        "    docs = []\n",
        "    try:\n",
        "        loader = PyPDFLoader(str(file_path))\n",
        "        docs = loader.load()\n",
        "    except Exception as e:\n",
        "        print(f\"‚ùå LangChain PyPDFLoader failed for {file_path}: {e}\")\n",
        "    return docs\n",
        "\n",
        "def load_single_pdf(file_path):\n",
        "    \"\"\"Try multiple PDF loading methods in order of preference\"\"\"\n",
        "    docs = []\n",
        "\n",
        "    # Try PyMuPDF first (usually best quality)\n",
        "    if PYMUPDF_AVAILABLE:\n",
        "        docs = load_pdf_with_pymupdf(file_path)\n",
        "        if docs:\n",
        "            return docs\n",
        "\n",
        "    # Try PyPDF2 as fallback\n",
        "    if PYPDF2_AVAILABLE:\n",
        "        docs = load_pdf_with_pypdf2(file_path)\n",
        "        if docs:\n",
        "            return docs\n",
        "\n",
        "    # Try LangChain's PyPDFLoader as last resort\n",
        "    docs = load_pdf_with_langchain(file_path)\n",
        "    return docs\n",
        "\n",
        "def load_single_txt(file_path):\n",
        "    \"\"\"Load a single text file\"\"\"\n",
        "    try:\n",
        "        return TextLoader(str(file_path)).load()\n",
        "    except Exception as e:\n",
        "        print(f\"‚ùå Failed to load {file_path}: {e}\")\n",
        "        return []\n",
        "\n",
        "def load_documents_parallel(file_paths, file_type):\n",
        "    \"\"\"Load documents in parallel\"\"\"\n",
        "    docs = []\n",
        "    load_func = load_single_pdf if file_type == 'pdf' else load_single_txt\n",
        "\n",
        "    with ThreadPoolExecutor(max_workers=min(len(file_paths), os.cpu_count())) as executor:\n",
        "        futures = {executor.submit(load_func, path): path for path in file_paths}\n",
        "\n",
        "        for future in tqdm(as_completed(futures), total=len(futures),\n",
        "                          desc=f\"Loading {file_type.upper()} files\", unit=\"file\"):\n",
        "            try:\n",
        "                result = future.result()\n",
        "                if result:\n",
        "                    docs.extend(result)\n",
        "            except Exception as e:\n",
        "                file_path = futures[future]\n",
        "                print(f\"‚ùå Failed to load {file_path}: {e}\")\n",
        "\n",
        "    return docs\n",
        "\n",
        "def build_db():\n",
        "    # 1. Load documents\n",
        "    print(\"üìÇ Loading .txt and .pdf files...\")\n",
        "\n",
        "    # Find all files\n",
        "    txt_files = list(DATA_DIR.rglob(\"*.txt\"))\n",
        "    pdf_files = list(DATA_DIR.rglob(\"*.pdf\"))\n",
        "\n",
        "    print(f\"Found {len(txt_files)} .txt files and {len(pdf_files)} .pdf files\")\n",
        "\n",
        "    if not txt_files and not pdf_files:\n",
        "        print(\"‚ùå No documents found.\")\n",
        "        return\n",
        "\n",
        "    # Load documents in parallel\n",
        "    all_docs = []\n",
        "\n",
        "    if txt_files:\n",
        "        txt_docs = load_documents_parallel(txt_files, 'txt')\n",
        "        all_docs.extend(txt_docs)\n",
        "        print(f\"‚úÖ Loaded {len(txt_docs)} text documents\")\n",
        "\n",
        "    if pdf_files:\n",
        "        pdf_docs = load_documents_parallel(pdf_files, 'pdf')\n",
        "        all_docs.extend(pdf_docs)\n",
        "        print(f\"‚úÖ Loaded {len(pdf_docs)} PDF pages\")\n",
        "\n",
        "    if not all_docs:\n",
        "        print(\"‚ùå No documents could be loaded.\")\n",
        "        return\n",
        "\n",
        "    print(f\"üìÑ Total documents loaded: {len(all_docs)}\")\n",
        "\n",
        "    # 2. Split documents in parallel\n",
        "    print(\"‚úÇÔ∏è  Splitting documents into chunks...\")\n",
        "    splitter = RecursiveCharacterTextSplitter(\n",
        "        chunk_size=512,\n",
        "        chunk_overlap=50,\n",
        "        separators=[\"\\n\\n\", \"\\n\", \" \", \"\"]  # Better for PDF content\n",
        "    )\n",
        "\n",
        "    chunks = []\n",
        "    with ThreadPoolExecutor(max_workers=os.cpu_count()) as executor:\n",
        "        futures = {executor.submit(splitter.split_documents, [d]): d for d in all_docs}\n",
        "        for future in tqdm(as_completed(futures), total=len(futures),\n",
        "                          desc=\"Splitting docs\", unit=\"doc\"):\n",
        "            try:\n",
        "                result = future.result()\n",
        "                chunks.extend(result)\n",
        "            except Exception as e:\n",
        "                print(f\"‚ùå Failed to split document: {e}\")\n",
        "                continue\n",
        "\n",
        "    print(f\"üìÑ Generated {len(chunks)} chunks from {len(all_docs)} documents.\")\n",
        "\n",
        "    # 3. Prepare Chroma directory\n",
        "    if CHROMA_PATH.exists():\n",
        "        import shutil\n",
        "        shutil.rmtree(CHROMA_PATH)\n",
        "    CHROMA_PATH.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "    # 4. Persist with parallel ingestion\n",
        "    print(\"üåê Ingesting chunks to Chroma with TPU embeddings in parallel...\")\n",
        "    embed_fn = TensorflowHubEmbeddings(model_url=EMBEDDING_MODEL_URL)\n",
        "    db = Chroma(\n",
        "        collection_name=CHROMA_COLLECTION_NAME,\n",
        "        persist_directory=str(CHROMA_PATH),\n",
        "        embedding_function=embed_fn\n",
        "    )\n",
        "\n",
        "    # Process in batches to avoid memory issues\n",
        "    batch_size = 50\n",
        "    batches = [chunks[i:i + batch_size] for i in range(0, len(chunks), batch_size)]\n",
        "\n",
        "    with ThreadPoolExecutor(max_workers=min(len(batches), os.cpu_count())) as executor:\n",
        "        futures = {executor.submit(db.add_documents, documents=batch): idx\n",
        "                  for idx, batch in enumerate(batches)}\n",
        "\n",
        "        for future in tqdm(as_completed(futures), total=len(futures),\n",
        "                          desc=\"Adding batches\", unit=\"batch\"):\n",
        "            try:\n",
        "                future.result()\n",
        "            except Exception as e:\n",
        "                batch_idx = futures[future]\n",
        "                print(f\"‚ùå Batch {batch_idx} failed: {e}\")\n",
        "\n",
        "    db.persist()\n",
        "\n",
        "    # 5. Save metadata\n",
        "    info = {\n",
        "        'created_at': time.strftime('%Y-%m-%d %H:%M:%S'),\n",
        "        'model_url': EMBEDDING_MODEL_URL,\n",
        "        'total_documents': len(all_docs),\n",
        "        'txt_files': len(txt_files),\n",
        "        'pdf_files': len(pdf_files),\n",
        "        'total_chunks': len(chunks),\n",
        "        'pdf_extraction_methods': {\n",
        "            'pymupdf_available': PYMUPDF_AVAILABLE,\n",
        "            'pypdf2_available': PYPDF2_AVAILABLE\n",
        "        }\n",
        "    }\n",
        "\n",
        "    with open(CHROMA_PATH / 'info.json', 'w') as f:\n",
        "        json.dump(info, f, indent=2)\n",
        "\n",
        "    print(\"‚úÖ Database built successfully.\")\n",
        "    print(f\"üìä Summary:\")\n",
        "    print(f\"   ‚Ä¢ Total documents: {len(all_docs)}\")\n",
        "    print(f\"   ‚Ä¢ Text files: {len(txt_files)}\")\n",
        "    print(f\"   ‚Ä¢ PDF files: {len(pdf_files)}\")\n",
        "    print(f\"   ‚Ä¢ Total chunks: {len(chunks)}\")\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    build_db()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "Av5c_L2OHot2"
      },
      "outputs": [],
      "source": [
        "!pip install python-dotenv tqdm langchain langchain-huggingface langchain-community chromadb tensorflow-hub tensorflow-text google-generativeai\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "tD3LOSR69Ent",
        "outputId": "b8dc0dbb-6b0e-4b62-b19d-5511e6f5f572"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "üîç Checking embedding model compatibility...\n",
            "‚ö†Ô∏è  No database info found. Cannot verify compatibility.\n",
            "ü§ñ Interactive QA with ChromaDB Retrieval + Google AI (FREE TIER)\n",
            "============================================================\n",
            "üìä Configuration:\n",
            "   ‚Ä¢ Embedding Model: Universal Sentence Encoder Large v5\n",
            "   ‚Ä¢ Google AI Model: gemini-1.5-flash\n",
            "   ‚Ä¢ Free Tier Limits: 15 requests/min, 1,500 requests/day\n",
            "============================================================\n",
            "üîß Initializing ChromaDB retriever...\n",
            "‚úÖ Embeddings initialized with model: https://tfhub.dev/google/universal-sentence-encoder-large/5\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-3-3941353216>:63: LangChainDeprecationWarning: The class `Chroma` was deprecated in LangChain 0.2.9 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-chroma package and should be used instead. To use it run `pip install -U :class:`~langchain-chroma` and import as `from :class:`~langchain_chroma import Chroma``.\n",
            "  db = Chroma(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "üìä Database contains 1750 documents\n",
            "‚úÖ Retriever initialized successfully!\n",
            "üîç Retrieving top 5 relevant documents per query\n",
            "\n",
            "Type your question and press Enter. Type 'exit' to quit.\n",
            "üí° Tip: Be specific in your questions for better results!\n",
            "============================================================\n",
            "\n",
            "üîç Your Question: django\n",
            "\n",
            "‚è≥ Searching documents...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-3-3941353216>:186: LangChainDeprecationWarning: The method `BaseRetriever.get_relevant_documents` was deprecated in langchain-core 0.1.46 and will be removed in 1.0. Use :meth:`~invoke` instead.\n",
            "  documents = retriever.get_relevant_documents(query)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ Found 5 relevant documents\n",
            "ü§ñ Generating answer with Google AI...\n",
            "\n",
            "============================================================\n",
            "üéØ ANSWER:\n",
            "============================================================\n",
            "Based on the provided text, Django is a web framework designed for rapid development of database-driven web applications.  It was developed in a fast-paced newsroom environment, making common web development tasks easier (Document 1).  The documentation includes sections on getting started for both beginners and experienced developers (Document 4), an overview of how Django works (Document 1, Document 3), and details on using the Django source code repository (Document 2).  Django includes an object-relational mapper (ORM) allowing database layout descriptions in Python code (Document 3).  A release version 1.0.2 is mentioned (Document 5).  For production environments, using official packaged releases is recommended (Document 2).\n",
            "\n",
            "\n",
            "============================================================\n",
            "üìñ SOURCES:\n",
            "============================================================\n",
            "Source 1: /content/drive/MyDrive/Google AI Studio/all_txt/overview_2.txt\n",
            "Source 2: /content/drive/MyDrive/Google AI Studio/all_txt/git_1.txt\n",
            "Source 3: /content/drive/MyDrive/Google AI Studio/all_txt/overview_2.txt\n",
            "Source 4: /content/drive/MyDrive/Google AI Studio/all_txt/index_14_1.txt\n",
            "Source 5: /content/drive/MyDrive/Google AI Studio/all_txt/1.0.2.txt\n",
            "\n",
            "üìÑ Show document previews? (y/n): n\n",
            "\n",
            "üîç Your Question: what is django\n",
            "\n",
            "‚è≥ Searching documents...\n",
            "‚úÖ Found 5 relevant documents\n",
            "ü§ñ Generating answer with Google AI...\n",
            "\n",
            "============================================================\n",
            "üéØ ANSWER:\n",
            "============================================================\n",
            "Based on the provided text, Django is a web framework developed in a fast-paced newsroom environment, designed to make common web development tasks fast and easy (Document 1).  It's primarily written in Python (Document 5) and includes an object-relational mapper (ORM) that allows users to describe their database layout in Python code (Document 2).  Django's source code is available on GitHub (Document 3), and extensive documentation is available, including tutorials for beginners (Documents 1, 4, and 5).  The documentation covers various aspects, from a quick overview (Document 1) to detailed guides on creating your first Django app (Document 4) and building reusable apps (Document 5).\n",
            "\n",
            "\n",
            "============================================================\n",
            "üìñ SOURCES:\n",
            "============================================================\n",
            "Source 1: /content/drive/MyDrive/Google AI Studio/all_txt/overview_2.txt\n",
            "Source 2: /content/drive/MyDrive/Google AI Studio/all_txt/overview_2.txt\n",
            "Source 3: /content/drive/MyDrive/Google AI Studio/all_txt/git_1.txt\n",
            "Source 4: /content/drive/MyDrive/Google AI Studio/all_txt/index_14_1.txt\n",
            "Source 5: /content/drive/MyDrive/Google AI Studio/all_txt/index_14_1.txt\n",
            "\n",
            "üëã Goodbye!\n"
          ]
        }
      ],
      "source": [
        "#!/usr/bin/env python3\n",
        "\n",
        "\"\"\"\n",
        "qa_with_google_ai.py - Interactive QA with ChromaDB retrieval and Google AI\n",
        "\n",
        "Features:\n",
        "  ‚Ä¢ Retrieves relevant documents from ChromaDB using TPU embeddings\n",
        "  ‚Ä¢ Uses Google's Gemini API to generate clear, contextual answers\n",
        "  ‚Ä¢ Interactive question-answering interface\n",
        "  ‚Ä¢ Updated to use Universal Sentence Encoder v5\n",
        "\"\"\"\n",
        "import os\n",
        "from pathlib import Path\n",
        "from dotenv import load_dotenv\n",
        "load_dotenv()\n",
        "\n",
        "import time\n",
        "from tqdm.auto import tqdm\n",
        "import google.generativeai as genai\n",
        "\n",
        "# Updated import for current LangChain version\n",
        "from langchain_community.embeddings import TensorflowHubEmbeddings\n",
        "from langchain_community.vectorstores import Chroma\n",
        "\n",
        "# API Configuration - Better to use environment variable\n",
        "GOOGLE_API_KEY = os.getenv('GOOGLE_API_KEY', \"AIzaSyCDhN63yAiXk5Z_zh3TIw50Cu5PD3MUMts\")\n",
        "os.environ['GOOGLE_API_KEY'] = GOOGLE_API_KEY\n",
        "genai.configure(api_key=GOOGLE_API_KEY)\n",
        "\n",
        "# Paths (ensure database is already built)\n",
        "CHROMA_PATH = Path('/content/drive/MyDrive/Google AI Studio/chroma_db_cloude')\n",
        "COLLECTION_NAME = 'rag_collection'\n",
        "\n",
        "# IMPORTANT: This must match the model used when creating the database\n",
        "EMBEDDING_MODEL_URL = 'https://tfhub.dev/google/universal-sentence-encoder-large/5'\n",
        "\n",
        "TOP_K = 5  # Retrieve more documents for better context\n",
        "\n",
        "# Google AI Model Configuration - Using FREE TIER\n",
        "MODEL_NAME = \"gemini-1.5-flash\"  # FREE: 15 req/min, 1M tokens/min, 1,500 req/day\n",
        "# Alternative free options:\n",
        "# \"gemini-1.5-pro\" - FREE: 2 req/min, 32k tokens/min, 50 req/day (higher quality)\n",
        "# \"gemini-1.5-flash-8b\" - FREE: 15 req/min, 1M tokens/min, 1,500 req/day (fastest)\n",
        "\n",
        "model = genai.GenerativeModel(MODEL_NAME)\n",
        "\n",
        "# Generation configuration optimized for free tier\n",
        "generation_config = genai.types.GenerationConfig(\n",
        "    temperature=0.1,  # Lower for more factual responses\n",
        "    top_p=0.8,\n",
        "    top_k=40,\n",
        "    max_output_tokens=1024,  # Reduced to save tokens on free tier\n",
        ")\n",
        "\n",
        "def initialize_retriever():\n",
        "    \"\"\"Initialize ChromaDB retriever with TPU embeddings\"\"\"\n",
        "    print(\"üîß Initializing ChromaDB retriever...\")\n",
        "\n",
        "    try:\n",
        "        embed_fn = TensorflowHubEmbeddings(model_url=EMBEDDING_MODEL_URL)\n",
        "        print(f\"‚úÖ Embeddings initialized with model: {EMBEDDING_MODEL_URL}\")\n",
        "\n",
        "        db = Chroma(\n",
        "            collection_name=COLLECTION_NAME,\n",
        "            persist_directory=str(CHROMA_PATH),\n",
        "            embedding_function=embed_fn\n",
        "        )\n",
        "\n",
        "        # Test if database exists and has data\n",
        "        collection = db._collection\n",
        "        doc_count = collection.count()\n",
        "        print(f\"üìä Database contains {doc_count} documents\")\n",
        "\n",
        "        if doc_count == 0:\n",
        "            raise ValueError(\"Database is empty. Please run the database creation script first.\")\n",
        "\n",
        "        retriever = db.as_retriever(search_kwargs={\"k\": TOP_K})\n",
        "        print(\"‚úÖ Retriever initialized successfully!\")\n",
        "        return retriever\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"‚ùå Failed to initialize retriever: {e}\")\n",
        "        if \"No such file or directory\" in str(e):\n",
        "            print(\"üí° Hint: Make sure you've run the database creation script first\")\n",
        "        elif \"model\" in str(e).lower():\n",
        "            print(\"üí° Hint: Ensure the embedding model URL matches the one used to create the database\")\n",
        "        raise\n",
        "\n",
        "def create_prompt(query, documents):\n",
        "    \"\"\"Create a prompt for Google AI with retrieved context\"\"\"\n",
        "    context = \"\\n\\n\".join([\n",
        "        f\"Document {i+1} (Source: {doc.metadata.get('source', 'Unknown')}):\\n{doc.page_content[:800]}\"\n",
        "        for i, doc in enumerate(documents)\n",
        "    ])\n",
        "\n",
        "    prompt = f\"\"\"You are a helpful assistant that answers questions based on the provided context documents.\n",
        "\n",
        "Context Documents:\n",
        "{context}\n",
        "\n",
        "Question: {query}\n",
        "\n",
        "Instructions:\n",
        "1. Answer the question based ONLY on the information provided in the context documents\n",
        "2. If the answer is not available in the context, clearly state that the information is not available\n",
        "3. Be specific and cite relevant details from the documents\n",
        "4. Provide a clear, well-structured answer\n",
        "5. If multiple documents contain relevant information, synthesize them coherently\n",
        "6. When possible, mention which document(s) the information comes from\n",
        "\n",
        "Answer:\"\"\"\n",
        "\n",
        "    return prompt\n",
        "\n",
        "def get_ai_response(prompt):\n",
        "    \"\"\"Get response from Google AI with rate limiting for free tier\"\"\"\n",
        "    try:\n",
        "        # Add a small delay to respect free tier rate limits\n",
        "        time.sleep(0.1)  # Prevents hitting 15 req/min limit too quickly\n",
        "\n",
        "        response = model.generate_content(\n",
        "            prompt,\n",
        "            generation_config=generation_config\n",
        "        )\n",
        "\n",
        "        if response.parts:\n",
        "            return response.text\n",
        "        else:\n",
        "            return \"‚ö†Ô∏è No response generated. The content might have been filtered.\"\n",
        "\n",
        "    except Exception as e:\n",
        "        error_msg = str(e)\n",
        "        if \"quota\" in error_msg.lower() or \"rate\" in error_msg.lower():\n",
        "            return \"‚ö†Ô∏è Rate limit reached. Please wait a moment and try again. Free tier allows 15 requests per minute.\"\n",
        "        elif \"safety\" in error_msg.lower():\n",
        "            return \"‚ö†Ô∏è Response was filtered due to safety settings. Try rephrasing your question.\"\n",
        "        return f\"‚ùå Error generating response: {error_msg}\"\n",
        "\n",
        "def format_sources(documents):\n",
        "    \"\"\"Format document sources for reference\"\"\"\n",
        "    sources = []\n",
        "    for i, doc in enumerate(documents, 1):\n",
        "        metadata = doc.metadata\n",
        "        source_info = f\"Source {i}: {metadata.get('source', 'Unknown')}\"\n",
        "        if 'page' in metadata:\n",
        "            source_info += f\" (Page {metadata['page']})\"\n",
        "        sources.append(source_info)\n",
        "    return \"\\n\".join(sources)\n",
        "\n",
        "def main():\n",
        "    print(\"ü§ñ Interactive QA with ChromaDB Retrieval + Google AI (FREE TIER)\")\n",
        "    print(\"=\" * 60)\n",
        "    print(\"üìä Configuration:\")\n",
        "    print(f\"   ‚Ä¢ Embedding Model: Universal Sentence Encoder Large v5\")\n",
        "    print(f\"   ‚Ä¢ Google AI Model: {MODEL_NAME}\")\n",
        "    print(f\"   ‚Ä¢ Free Tier Limits: 15 requests/min, 1,500 requests/day\")\n",
        "    print(\"=\" * 60)\n",
        "\n",
        "    # Initialize retriever\n",
        "    try:\n",
        "        retriever = initialize_retriever()\n",
        "    except Exception as e:\n",
        "        print(f\"‚ùå Failed to initialize system: {e}\")\n",
        "        return\n",
        "\n",
        "    print(f\"üîç Retrieving top {TOP_K} relevant documents per query\")\n",
        "    print(\"\\nType your question and press Enter. Type 'exit' to quit.\")\n",
        "    print(\"üí° Tip: Be specific in your questions for better results!\")\n",
        "    print(\"=\" * 60)\n",
        "\n",
        "    while True:\n",
        "        try:\n",
        "            # Get user query\n",
        "            query = input(\"\\nüîç Your Question: \").strip()\n",
        "\n",
        "            if query.lower() in ('exit', 'quit', 'q'):\n",
        "                print(\"üëã Goodbye!\")\n",
        "                break\n",
        "\n",
        "            if not query:\n",
        "                continue\n",
        "\n",
        "            print(\"\\n‚è≥ Searching documents...\")\n",
        "\n",
        "            # Retrieve relevant documents\n",
        "            documents = retriever.get_relevant_documents(query)\n",
        "\n",
        "            if not documents:\n",
        "                print(\"‚ùå No relevant documents found in the database.\")\n",
        "                print(\"üí° Try rephrasing your question or using different keywords.\")\n",
        "                continue\n",
        "\n",
        "            print(f\"‚úÖ Found {len(documents)} relevant documents\")\n",
        "            print(\"ü§ñ Generating answer with Google AI...\")\n",
        "\n",
        "            # Create prompt and get AI response\n",
        "            prompt = create_prompt(query, documents)\n",
        "            ai_response = get_ai_response(prompt)\n",
        "\n",
        "            # Display results\n",
        "            print(\"\\n\" + \"=\"*60)\n",
        "            print(\"üéØ ANSWER:\")\n",
        "            print(\"=\"*60)\n",
        "            print(ai_response)\n",
        "\n",
        "            print(\"\\n\" + \"=\"*60)\n",
        "            print(\"üìñ SOURCES:\")\n",
        "            print(\"=\"*60)\n",
        "            print(format_sources(documents))\n",
        "\n",
        "            # Optional: Show document previews\n",
        "            show_docs = input(\"\\nüìÑ Show document previews? (y/n): \").strip().lower()\n",
        "            if show_docs == 'y':\n",
        "                print(\"\\n\" + \"=\"*60)\n",
        "                print(\"üìã DOCUMENT PREVIEWS:\")\n",
        "                print(\"=\"*60)\n",
        "                for i, doc in enumerate(documents, 1):\n",
        "                    print(f\"\\n--- Document {i} Preview ---\")\n",
        "                    preview = doc.page_content[:300] + \"...\" if len(doc.page_content) > 300 else doc.page_content\n",
        "                    print(preview)\n",
        "                    print(\"-\" * 30)\n",
        "\n",
        "        except KeyboardInterrupt:\n",
        "            print(\"\\nüëã Goodbye!\")\n",
        "            break\n",
        "        except Exception as e:\n",
        "            print(f\"‚ùå Error: {str(e)}\")\n",
        "            print(\"Please try again with a different question.\")\n",
        "\n",
        "def test_system():\n",
        "    \"\"\"Test function to verify the system works\"\"\"\n",
        "    print(\"üß™ Testing the QA system...\")\n",
        "\n",
        "    try:\n",
        "        retriever = initialize_retriever()\n",
        "        test_queries = [\n",
        "            \"What is this document about?\",\n",
        "            \"Tell me about the main topics covered\",\n",
        "            \"What are the key points mentioned?\"\n",
        "        ]\n",
        "\n",
        "        for query in test_queries:\n",
        "            print(f\"Testing query: {query}\")\n",
        "            documents = retriever.get_relevant_documents(query)\n",
        "\n",
        "            if documents:\n",
        "                print(f\"‚úÖ Retrieved {len(documents)} documents\")\n",
        "                prompt = create_prompt(query, documents[:2])  # Test with 2 docs\n",
        "                response = get_ai_response(prompt)\n",
        "                print(f\"AI Response preview: {response[:150]}...\")\n",
        "                break\n",
        "            else:\n",
        "                print(\"‚ùå No documents found for this query\")\n",
        "\n",
        "        return len(documents) > 0\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"‚ùå System test failed: {e}\")\n",
        "        return False\n",
        "\n",
        "def check_embedding_compatibility():\n",
        "    \"\"\"Check if the embedding model matches the database\"\"\"\n",
        "    print(\"üîç Checking embedding model compatibility...\")\n",
        "\n",
        "    info_file = CHROMA_PATH / 'info.json'\n",
        "    if info_file.exists():\n",
        "        import json\n",
        "        with open(info_file, 'r') as f:\n",
        "            db_info = json.load(f)\n",
        "\n",
        "        db_model = db_info.get('model_url', 'Unknown')\n",
        "        current_model = EMBEDDING_MODEL_URL\n",
        "\n",
        "        print(f\"Database model: {db_model}\")\n",
        "        print(f\"Current model:  {current_model}\")\n",
        "\n",
        "        if db_model != current_model:\n",
        "            print(\"‚ö†Ô∏è  WARNING: Embedding model mismatch detected!\")\n",
        "            print(\"This will cause poor retrieval performance.\")\n",
        "            print(\"Please update the EMBEDDING_MODEL_URL to match your database.\")\n",
        "            return False\n",
        "        else:\n",
        "            print(\"‚úÖ Embedding models match!\")\n",
        "            return True\n",
        "    else:\n",
        "        print(\"‚ö†Ô∏è  No database info found. Cannot verify compatibility.\")\n",
        "        return None\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    # Check compatibility first\n",
        "    check_embedding_compatibility()\n",
        "\n",
        "    # Uncomment the next line to run a quick test first\n",
        "    # test_system()\n",
        "\n",
        "    main()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "04a5cbc1a6ce460094b8f76ae284c206": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7f082831e6474788ae19ac9c386829ad",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_7180a10ed0b443d98e645aa75e17f31a",
            "value": "Adding‚Äábatches:‚Äá100%"
          }
        },
        "0e6d093d41344fc09650686b34433acc": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "105b4489a8b0425eab93d320bbbfb834": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1648066ad3f04af5931fcf29d5635f63": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "1c2b957fc6384db4a84b040adc9d8383": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f77b94b7c70944aaa54d157f41c7a8fa",
            "max": 1777,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_f053eba232464219a0122adc4fb51c30",
            "value": 1777
          }
        },
        "24f632c63db3441fb6673f8b6039b379": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "2d72a629aab444caa10cb1e213d5f595": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_58a7af7b84194c3181269b8e1d1e220f",
            "max": 1037,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_24f632c63db3441fb6673f8b6039b379",
            "value": 1037
          }
        },
        "4ce102cdeed94d1094e3dcfdf41d9717": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4daf6dd9ea17401daec5ab9a7c3251b0": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_04a5cbc1a6ce460094b8f76ae284c206",
              "IPY_MODEL_2d72a629aab444caa10cb1e213d5f595",
              "IPY_MODEL_c19e6df98ecc4cdeb0e6ea9208b358b4"
            ],
            "layout": "IPY_MODEL_d41d1a0710be44e98f3fb986a49ba293"
          }
        },
        "58a7af7b84194c3181269b8e1d1e220f": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5cb0c62103444025bf3ca674045f1000": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6bdfacf8841c4651af99734bde0e2a46": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "6f3dba7bec4642d6a3f3996bbf37644e": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7180a10ed0b443d98e645aa75e17f31a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "71940fd74e9c4e4da1521f08c5d48bb2": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "7f082831e6474788ae19ac9c386829ad": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "81eb2895b214464e9762b1c294cf1cf3": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8485c82514ea45d0925aac27b446e77a",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_1648066ad3f04af5931fcf29d5635f63",
            "value": "‚Äá1777/1777‚Äá[00:00&lt;00:00,‚Äá81553.74doc/s]"
          }
        },
        "8485c82514ea45d0925aac27b446e77a": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "85be9aafc0f14a90a59212579fa871b1": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "917340856dcd43b4b89396d48e6554e2": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9527798d94e644c89121485a08913298": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6f3dba7bec4642d6a3f3996bbf37644e",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_85be9aafc0f14a90a59212579fa871b1",
            "value": "Splitting‚Äádocs:‚Äá100%"
          }
        },
        "9cc4f3388c564bdfbb3da5c0ee6ff878": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_9527798d94e644c89121485a08913298",
              "IPY_MODEL_1c2b957fc6384db4a84b040adc9d8383",
              "IPY_MODEL_81eb2895b214464e9762b1c294cf1cf3"
            ],
            "layout": "IPY_MODEL_5cb0c62103444025bf3ca674045f1000"
          }
        },
        "b231c6538b6c4139b0eb13b30fc2d76e": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b5d244dade2c4552bfaddeaa93443c2a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "be2e331a34344aceaea07fd561e823ac": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_c08ad26d464049e1b163f71b3875d334",
              "IPY_MODEL_fa64efd1b14a4a4e82c35788e337239e",
              "IPY_MODEL_c387c8882da2494b9f13afc6865348f8"
            ],
            "layout": "IPY_MODEL_0e6d093d41344fc09650686b34433acc"
          }
        },
        "c08ad26d464049e1b163f71b3875d334": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4ce102cdeed94d1094e3dcfdf41d9717",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_c3871565dbba4600b0147483d891689b",
            "value": "Loading‚ÄáTXT‚Äáfiles:‚Äá100%"
          }
        },
        "c19e6df98ecc4cdeb0e6ea9208b358b4": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_917340856dcd43b4b89396d48e6554e2",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_6bdfacf8841c4651af99734bde0e2a46",
            "value": "‚Äá1037/1037‚Äá[37:43&lt;00:00,‚Äá‚Äá1.37s/batch]"
          }
        },
        "c3871565dbba4600b0147483d891689b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c387c8882da2494b9f13afc6865348f8": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_105b4489a8b0425eab93d320bbbfb834",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_71940fd74e9c4e4da1521f08c5d48bb2",
            "value": "‚Äá1777/1777‚Äá[00:13&lt;00:00,‚Äá842.89file/s]"
          }
        },
        "d41d1a0710be44e98f3fb986a49ba293": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f053eba232464219a0122adc4fb51c30": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "f77b94b7c70944aaa54d157f41c7a8fa": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fa64efd1b14a4a4e82c35788e337239e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b231c6538b6c4139b0eb13b30fc2d76e",
            "max": 1777,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_b5d244dade2c4552bfaddeaa93443c2a",
            "value": 1777
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
